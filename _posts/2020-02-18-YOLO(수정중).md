---
layout: post
title:  "YOLO(수정중)"
date:   2020-02-18 17:58:13
categories: Deep_Learning
---



# YOLO - You Only Look Once : Unified, Real-Time Object Detection



### 목표는 직관성

사람은 눈이 가려진 채 원래 있던 공간에서 새로운 공간으로 이동해도 눈을 가리고 있는 가림막을 치움과 동시에 직관적으로 눈에 보이는 모든 시각정보를 해석한다. 인간은 이러한 직관적인 시각정보 해석에 익숙하다보니 이것이 얼마나 우리의 반응속도에 영향을 끼치는지 간과할 때가 많다.

직관적이고 즉각적인 시각정보 해석은 한 단어와 아주 밀접한 관계를 갖고 있다. 우리가 기계나 시스템을 만들때 가장 기본이 되면서 가장 궁극적으로 이루어야 할 목표인 단어, 그것은 바로 '실시간' 이다. 

인간은 현재를 살아가는 동물이고, 기계또한 인간의 생활에 맞추어 실시간으로 과제를 수행하고 결과물을 제시해 주기를 바란다. 즉 '실시간'으로 동작을 수행하고, 매 상황마다 등장하는 조건들을 최대한 빠르게 만족시키는 동작을 하는 것이 기계의 성능지표가 되는 것이다.

그렇다면 인공지능 분야에서 '실시간'은 얼마나 중요할까? 만일 물체를 인식하는 프로그램이 실시간으로 작동한다면 그 프로그램은 무한한 분야에서 응용될 수 있다. 예를 들면 실시간으로 장애물을 감지해낼 수 있는 프로그램은 모든 운송, 배송 분야에서 사용이 되어 자율주행을 통해 완벽한 자동화를 이룰 수 있다.

물체를 인식하는 방법은 여러가지가 있다. 그 중 앞에서 공부한 R-CNN(Regions with CNN features)은 입력된 이미지로부터 물체가 존재할 적절한 위치에 박스를 치는 후보들을 만들고, 생성된 다수의 후보들을 Resampling하여 동일한 크기로 만들어준 다음 모든 후보에 대해 CNN을 거쳐 물체를 인식해낸다. 이는 엄청난 연산량이 필요한 작업이기 때문에 후에 Fast R-CNN, Faster R-CNN이라는 개념들이 등장하였지만 이는 만들어진 후보에 대한 연산을 줄이는 방법이기 때문에 근본적으로 후보를 만드는데 필요한 연산은 크게 줄어들지 않았다. 

YOLO에서는 R-CNN과는 다르게 문제해결에 접근하여 물체를 인식하는데 걸리는 시간을 줄이는 것을 목표로 개발되었다.



### object detection에 대한 새로운 접근

YOLO는 object detection을 하나의 regression 문제로 구성한다. 즉 이미지 자체의 픽셀과 박스의 좌표, 그리고 레이블에 대한 확률만으로 물체를 인식한다.



### 참신한 간단함과 그에 따른 장점

![](https://raw.githubusercontent.com/Jonsuff/MLstudy/master/images/YOLO_figure1.png)

위의 YOLO Detection System에 대한 사진을 보면 물체를 인식하는데 거쳐야 할 3가지 단계가 표시되어 있는걸 볼 수 있다. 단 하나의 convolutional network를 거치면서 전체적인 이미지를 통해 실시간으로 박스를 예측하고 해당 박스들에 대한 확률을 계산하여 물체를 인식해낸다. 이는 다음과 같은 세가지의 대표적인 장점과 연결된다.

1. 연산속도가 엄청 빠르다.
2. 물체에 대한 예측을 이미지 전체를 통해 진행한다.
3. 물체에 대한 일반화된 성질을 학습한다.

당연히 단층구조의 네트워크로 연산을 처리하기 때문에 연산속도는 빠르다. 또한 이미지 전체를 사용하여 예측을 진행하기 때문에 인간이 직관적으로 물체를 파악하는것과 동작을 해낼 수 있다(픽셀별로 슬라이드를 넘겨가며 물체를 인식하지 않기 때문에 물체를 인식하는 과정을 사람이 이해할수 있다). 마지막으로 사람이 납득할만한 방식으로 물체를 인식하고 학습을 하기 때문에 사진이 아닌 그림에서 물체를 인식할때 높은 성능을 보인다. 또한 새로운 환경이나 예상치 못한 입력에도 쉽게 고장나지 않는다.



### 그러나 명확한 단점은 존재한다.

위에서 YOLO가 마치 모든 딥러닝 모델보다 좋은것처럼 칭찬을 해놨지만, YOLO에도 분명 단점은 존재한다. 정확도 측면에서 비슷한 시기에 등장한 모델들보다 성능이 떨어지는 것은 당연하고, 순간적으로 빠르게 물체를 감지해낼순 있으나 물체가 어디에 정확하게 위치하고 있는지는 잘 파악하지 못한다(특히 작은 물체일수록). 앞선 모델들보다 월등한 연산속도를 가진것에 대한 tradeoff로 생각하고 적절한 때 YOLO를 사용하면 된다.



### 연산과정 한눈에 보기



![](https://raw.githubusercontent.com/Jonsuff/MLstudy/master/images/YOLO_figure2.png)

YOLO 연산과정에 대해 알아보자.

1. 입력 데이터를 SxS개의 칸으로 나눈다.

2. Selective Search 방법을 사용하여 B개의 Bounding box를 찾아낸다.

3. 각각의 Bounding box에 대해 confidence score를 부여한다.

   여기서 confidence score란 해당 bounding box가 물체를 포함하고 있는지, 그리고 얼마나 그 box가 잘 예측을 했는지에 대한 지표이다. 보통은 물체가 포함된 정도에 IOU(intersection over union)을 곱하여 수치로 나타낸다. 만을 물체가 box에 포함되지 않았다면 이 수치는 0이 된다.

4. 1번에서 나눈 각각의 grid cell에서 클래스 레이블에 대한 확률을 계산하고(Bounding box의 개수와 상관없이 cell에 대한 예측만 진행한다), 이를 통해 인식을 마무리한다.

각각의 Bounding box는 5개의 예측이 들어있다(x, y, w, h, confidence).

1. x와 y는 (x,y)의 좌표 형태로 Bounding box의 정중앙 좌표를 의미한다.
2. w는 Bounding box의 너비를 의미한다.
3. h는 Bounding box의 높이를 의미한다.
4. confidence는 이미지와 예측간의 IOU를 의미한다.

결과적으로 SxS grid로 이미지를 나누었을때 텐서 연산을 따져보면 다음과 같다.
$$
\\S \times S \times(B*5+C)\\
$$
위에서 B는 Bounding box의 수, C는 클래스 레이블 수 이다.

