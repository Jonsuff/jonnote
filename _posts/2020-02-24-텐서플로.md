---
layout: post
title:  "13장 텐서플로"
date:   2020-02-24 16:00:13
categories: Machine_Learning
---



# CH.13 텐서플로



## 텐서플로란?

- 텐서플로는 머신러닝 작업 속도를 크게 높여주는 구글의 머신러닝 오픈소스 라이브러리 이다. 

- 텐서플로(TensorFlow)는 단어 그대로 Tensor의 Flow(흐름)이다.

- Tensor = Multi-dimensional Arrays = Data : 

  텐서는 다차원 행렬을 뜻하고, 이는 곧 딥러닝에 사용되는 데이터가 된다. 다시 말해 텐서는 스칼라, 벡터, 행렬 등이 일반화된 것으로 생각할 수 있다.

  - 스칼라 : 하나의 숫자, 즉 크기만을 의미하는 단위.

    > 랭크 0 텐서

    

  - 벡터 : 수학적으로 방향과 크기의 의미를 모두 포함하는 표현 도구이다. 

    방향이 존재한다는 것은 출발점과 도착점이 존재한다는 뜻이고, 이는 단순한 숫자 하나로는 표현되지 않는다. 따라서 벡터는 서로 의미있는 스칼라들의 집합이다.

    > 랭크 1 텐서

    

  - 행렬 : 수학적으로 수, 또는 문자를 괄호안에 직사각형 형태로 배열한 것이다.

    직사각형 형태라는 것은 각각의 행들과 각각의 열들은 서로 원소(element)의 갯수가 같다는 것이고, 이는 벡터들이 층층이 연결되어있다고(concatenate) 생각할 수 있다. 즉 행렬은 벡터들의 집합이다.

    > 랭크 2 텐서

    

- 텐서플로에서 계산은 데이터 플로우 그래프(data flow graph)로 행해진다.

  - Data flow graph : 프로그램이 수행하고자 하는 작업을 각 개별 연산들의 의존 관계 및 선후 관계에 맞추어 그래프 형식으로 나타내는 것.
  - 병렬적으로 연산을 수행하는 기초가 된다.

- CPU, GPU 모두를 연산과정에서 사용할 수 있고, 공식적으로 CUDA 기반의 GPU를 지원한다.

  - CUDA(Compute Unified Device Architecture) : GPU에서 수행하는 병렬 처리 알고리즘을 우리가 일반적으로 사용하는 프로그래밍 언어(C, 파이썬 등)를 사용하여 작성할 수 있도록 하는 GPGPU(General-Purpose computing on Graphics Processing Units, GPU 상의 범용 계산) 기술이다.

- Keras라는 별도의 라이브러리를 얹어서 사용하면 입문자들이 보다 간결하고 쉽게 딥러닝 모델을 만들 수 있다.



## 텐서플로 1.x vs 2.x

### 텐서플로 1.x버전

```python
## 그래프를 생성
g = tf.Graph()
with g.as_default():
    x = tf.compat.v1.placeholder(dtype=tf.float32,
                       shape=(None), name='x')
    w = tf.Variable(2.0, name='weight')
    b = tf.Variable(0.7, name='bias')

    z = w*x + b
    ## g 그래프에 init Node 생성
    init = tf.compat.v1.global_variables_initializer()

## 세션을 만들고 그래프 g를 전달
with tf.compat.v1.Session(graph=g) as sess:
    ## w와 b를 초기화
    sess.run(init)
    ## z를 평가
    for t in [1.0, 0.6, -1.8]:
        print('x=%4.1f --> z=%4.1f'%(
              t, sess.run(z, feed_dict={x:t})))
```

- 입력데이터를 위해 플레이스홀더(placeholder, 위에선 x)를 정의하고, 가중치 행렬을 정의한 후 입력에서부터 출력까지 연결된 모델을 만든다. 

  모델을 만들고 나서 세션을 만들고, 모델에 만들때 정의된 변수들을 초기화 해준다. 앞에서 플레이스홀더를 만들때 입력 데이터의 크기를 지정하지 않았기 때문에 세션에서 배치 데이터를 한 번에 전달하여 원소들을 차례대로 모델에 주입할 수 있다.

- 텐서 z를 출력하면 다음과 같은 결과가 나온다.

  ```
  Tensor("add:0", dtype=float32)
  ```

  여기서 텐서 이름 add:0은 z가 덧셈 연산의 첫 번째 출력이라는 것을 알려준다. 텐서 z에는 실제로 어떤 값도 들어 있지 않고, 세션을 열어서 텐서 z를 평가해야만 값을 얻어낼 수 있다.

  이처럼 이전의 텐서플로 버전에서는 그래프의 정의 단계와 실행 단계로 나뉘어져 있다.



### 동일한 계산 with 텐서플로 2.x 버전

```python
## TF 2.0

w = tf.Variable(2.0, name='weight')
b = tf.Variable(0.7, name='bias')

# z를 평가합니다.
for x in [1.0, 0.6, -1.8]:
    z = w * x + b
    print('x=%4.1f --> z=%4.1f'%(x, z))
    
# for문 없이 리스트로 연산하기
z = w*[1., 2., 3.]+b
# numpy() 메서드를 사용하여 텐서값을 넘파이 배열로 출력
print(z.numpy())

```

- 텐서플로 2.x버전이 등장하면서 Session 객체를 만들어 플레이스홀더에 데이터를 주입하는 방식은 불필요해졌다. 대신 파이썬 리스트를 사용하여 직접 z값을 계산할 수 있으며 변수 초기화 과정도 불필요하다.

- 앞에서처럼 텐서 z를 출력해보면 다음과 같은 결과가 나온다.

  ```
  tf.Tensor(-2.8999999, shape=(), dtype=float32)
  ```

  여기서 z는 덧셈 연산의 출력 텐서가 아니라 실제로 값을 가지고 있는 텐서이다. 위의 for문에서 마지막 연산이였던 -1.8이 입력되어 나온 결과인 -2.9가 저장되어 있는것을 볼 수 있다.



## 배열 구조 다루기

```python
import tensorflow as tf
import numpy as np

## 3x2x3 행렬 생성
x_array = np.arange(18).reshape(3, 2, 3)

## 마지막 차원에 6개의 값으로 고정되도록 모양 조정
## 이때 결과로 나오는 행렬은 3x6
x2 = tf.reshape(x_array, shape=(-1, 6))

## 각 열의 합을 계산
xsum = tf.reduce_sum(x2, axis=0)

## 각 열의 평균을 계산
xmean = tf.reduce_mean(x2, axis=0)

print('입력 크기: ', x_array.shape)
print('크기가 변경된 입력:\n', x2.numpy())
print('열의 합:\n', xsum.numpy())
print('열의 평균:\n', xmean.numpy())
```

- 3x2x3 행렬의 모습을 다음과 같이 numpy array로 표현
  $$
  \\
  \begin{bmatrix}\begin{bmatrix}\begin{bmatrix}0 & 1 & 2  \end{bmatrix}\\\begin{bmatrix}3 & 4 & 5  \end{bmatrix}  \end{bmatrix} \\ \begin{bmatrix} \begin{bmatrix}6 & 7 & 8  \end{bmatrix}\\  \begin{bmatrix}9 & 10 & 11  \end{bmatrix}  \end{bmatrix} \\\begin{bmatrix} \begin{bmatrix}12 & 13 & 14  \end{bmatrix}\\  \begin{bmatrix}15 & 16 & 17  \end{bmatrix}  \end{bmatrix} \end{bmatrix}
  \\
  $$

- tf.reshape(x, shape = (-1,6))의 결과
  $$
  \\
  \begin{bmatrix} \begin{bmatrix}0 & 1 & 2 & 3 & 4 & 5 \end{bmatrix}\\  \begin{bmatrix}6 & 7 & 8 & 9 & 10 & 11 \end{bmatrix} \\ \begin{bmatrix}12 & 13 & 14 & 15 & 16 & 17 \end{bmatrix}  \end{bmatrix}
  \\
  $$
  

## 텐서플로 저수준 API로 간단한 모델 개발

> 최소 제곱법 회귀 구현

```python
import tensorflow as tf
import numpy as np
 
X_train = np.arange(10).reshape((10, 1))
y_train = np.array([1.0, 1.3, 3.1,
                    2.0, 5.0, 6.3, 
                    6.6, 7.4, 8.0, 
                    9.0])

class TfLinreg(object):
    
    def __init__(self, learning_rate=0.01):
        ## 가중치와 절편을 정의
        self.w = tf.Variable(tf.zeros(shape=(1)))
        self.b = tf.Variable(tf.zeros(shape=(1)))
        ## 확률적 경사하강법 (Stochastic gradient decent) 옵티마이저를 설정
        self.optimizer = tf.keras.optimizers.SGD(lr=learning_rate)
        		
    def fit(self, X, y, num_epochs=10):
        ## 비용 함수의 값을 저장하기 위한 리스트를 정의합니다.
        training_costs = []
        for step in range(num_epochs):
            ## 자동 미분(주어진 입력 변수에 대한 연산의 gradient를 계산하는 것)을 위해 연산 과정을 기록합니다.
            with tf.GradientTape() as tape:
                z_net = self.w * X + self.b
                z_net = tf.reshape(z_net, [-1])
                sqr_errors = tf.square(y - z_net)
                ## 전체 평균 계산
                mean_cost = tf.reduce_mean(sqr_errors)
            ## 비용 함수에 대한 가중치의 그래디언트를 계산합니다. (b,w에 대한 mean_cost의 미분값)
            grads = tape.gradient(mean_cost, [self.w, self.b])
            ## 옵티마이저에 그래디언트를 반영합니다.
            self.optimizer.apply_gradients(zip(grads, [self.w, self.b]))
            ## 비용 함수의 값을 저장합니다.
            training_costs.append(mean_cost.numpy())
        return training_costs
    
    ## 만들어진 회귀모델에 예측을 만들기 위해 메서드 추가. z_net과 동일한 계산을 수행한다.
    def predict(self, X):
        return self.w * X + self.b
    
    
lrmodel = TfLinreg()
training_costs = lrmodel.fit(X_train, y_train)
```

결과 : 

![](https://raw.githubusercontent.com/Jonsuff/MLstudy/master/images/OLS회귀 with tensorflow.png)



위에서 만든 예측을 모델과 비교

```python
plt.scatter(X_train, y_train,
            marker='s', s=50,
            label='Training Data')
plt.plot(range(X_train.shape[0]), 
         lrmodel.predict(X_train),
         color='gray', marker='o', 
         markersize=6, linewidth=3,
         label='LinReg Model')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.tight_layout()
plt.show()
```

결과 : 

![](https://raw.githubusercontent.com/Jonsuff/MLstudy/master/images/OLS%ED%9A%8C%EA%B7%80%20with%20tensorflow_%EC%98%88%EC%B8%A1.png)





## tf.keras API로 다층 신경망 훈련

케라스는 텐서플로 위에 얹어서 사용하는 라이브러리로, 매우 직관적이고 사용하기 쉬운 API를 가진것이 특징이다. 텐서플로 1.4.0 릴리스부터는 케라스가 contrib 서브모듈 밖으로 이동하여 핵심 모듈이 되었다.



### MNIST 데이터셋의 손글씨 숫자를 분류

```python
model = tf.keras.models.Sequential()

# 50개 유닛을 가진 연결 층 모델에 추가. activation은 하이퍼볼릭 탄젠트사용
model.add(
    tf.keras.layers.Dense(
        units=50,    
        input_dim=X_train_centered.shape[1],
        kernel_initializer='glorot_uniform', # 새로운 가중치 행렬 초기화 알고리즘
        bias_initializer='zeros',
        activation='tanh'))

# 또 하나 추가
model.add(
    tf.keras.layers.Dense(
        units=50,    
        input_dim=50,
        kernel_initializer='glorot_uniform',
        bias_initializer='zeros',
        activation='tanh'))

## 출력층의 유닛 개수는 고유한 클래스 레이블 갯수와 같아야 함. 원핫 인코딩된 클래스 레이블 배열의 열 개수
model.add(
    tf.keras.layers.Dense(
        units=y_train_onehot.shape[1],    
        input_dim=50,
        kernel_initializer='glorot_uniform',
        bias_initializer='zeros',
        activation='softmax'))

## 훈련을 수행하기 전 모델 컴파일. 최적화할 손실 함수 정의 및 최적화에 사용할 경사하강법 옵티마이저 선택. 여기선 SGD 선택함
sgd_optimizer = tf.keras.optimizers.SGD(
    lr=0.001, decay=1e-7, momentum=.9)

model.compile(optimizer=sgd_optimizer,
              loss='categorical_crossentropy')
```

