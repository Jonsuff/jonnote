---
layout: post
title:  "LeNet-5"
date:   2020-01-13 18:43:13
categories: Deep_Learning
---



# LeNet-5

- LeNet-5 모델은 논문 **Gradient-Based Learning Applied to Document Recognition**-by Y. LeCun 에서 제시된 모델이며 이 모델로 손글씨 데이터를 학습하고 인식하였다.

### LeNet의 구조

![](https://raw.githubusercontent.com/Jonsuff/MLstudy/master/images/LeNet-5_image.png)

- Layer 순서 및 특징

  1. 입력 데이터는 32x32 크기의 이미지 이다. 이는 입력된 모든 손글씨 데이터보다 더 큰 값이다. (가장 큰 글씨도 28x28 배경 안에 20x20의 크기로 가운데에 위치한 형태이다.) 

     데이터보다 입력 이미지를 더 크게 설정한 이유는 특징점이 될 가능성이 높은 곡선이나 끝점, 혹은 갈라지는 부분이 최대한 이미지의 가운데에 위치하도록 하기 위함이다.

  2. C1 레이어는 Convolutional layer 이다. 이 레이어에서는 5x5 Convolution 연산을 통해 28x28 사이즈의 6개 feature map을 생성한다.

     - $$
       Size ={Size(input) - Size(filter) \over 1}+1= {32-5 \over 1}+1 = 28
       $$

     이때 5x5 Convolution filter에 bias가 더해져서 하나의 feature map을 만든다. 즉 $$5*5+1 = 26$$ 개의 파라미터가 한 feature map에 생성되고, 이것이 6개가 있으므로 총 자유 파라미터 개수는 $$26*6=156$$ 개 이다.

  3. S2 레이어는 sub-sampling layer 이다. 이 레이어에서는 feature map의 크기를 14x14로 줄인다. 이때 Average pooling을 수행하여 크기를 축소한다.

     각각의 feature map마다 1개의 weight와 1개의 bias가 있다. 따라서 총 자유 파라미터 개수는 12개 이다.

  4. C3 레이어는 Convolutional layer 이다. 이 레이어에서는 5x5 Convolution 연산을 통해 10x10 사이즈의 16개의 feature map을 생성한다.

     - $$
       Size ={Size(input) - Size(filter) \over 1}+1= {14-5 \over 1}+1 = 10
       $$

     이때 6개의 feature map을 모든 출력에 연결하지 않고 다음과 같이 선택적으로 입력 영상을 골라서 출력 영상과 연결한다.

     ![](https://raw.githubusercontent.com/Jonsuff/MLstudy/master/images/LeNet-5_C3_Table.png)

     이렇게 하는 이유는 순차적 연결에서 발생할 수 있는 연결의 symmetry(대칭성, 균형)를 깨주어 처음 convolution에서 얻은 6개의 low-level feature를 서로 다른 조합으로 섞이게 하기 위함이다. 

     이러한 연결로 인해 이 레이어의 자유 파라미터 개수는 5x5 filter에 의한 25와 S2와 C3의 연결 개수 60을 곱하고 16개의 feature map에 있는 각각 1개씩의 bias 16을 더한 1516개가 된다.

     - $$25*60+16 = 1516$$
     
  5. S4 레이어에서 Subsampling 하여(S2와 같이 average pooling을 사용) feature map의 크기를 5x5로 줄인다. 
  
     S2와 마찬가지로 각각 feature map마다 1개의 weight와 1개의 bias 파라미터가 있기 때문에 총 자유 파라미터 개수는 32개 이다.
  
  6. C5에서는 Subsampling된 5x5 데이터에 5x5 convolution 연산을 통해 1x1 사이즈의 120개 feature map을 생성한다.
  
     S4의 모든 feature map이 C5의 feature map과 연결되어 자유 파라미터 개수는 5x5 filter에 의한 25와 S4의 feature map의 개수인 16과 C5의 feature map 개수인 120을 곱하고 마지막으로 120개의 bias를 더해주어 총 48120개가 된다
  
     - $$25*16*120+120 = 48120$$
  
  7. 마지막 단계인 F6에서는 Fully connected neural network로 C5의 결과를 84개의 unit에 연결시킨다.
  
     자유 파라미터의 개수는 C5의 feature map 개수인 120과 F6의 unit수인 84를 곱하고 84개의 bias를 더하여 총 10164개가 된다.
  
     - $$120*84+84=10164$$ 
  
  8. 단계별 이미지는 다음과 같다.
  
     ![](https://raw.githubusercontent.com/Jonsuff/MLstudy/master/images/LeNet_image_example_by_layer.png)