---
layout: post
title:  "YOLOv4"
date:   2020-09-10 13:56:13
categories: Deep_Learning
---



# YOLOv4

| 제목 | YOLOv4: Optimal Speed and Accuracy of Object Detection  |
| ---- | :-----------------------------------------------------: |
| 저자 | Alexey Bochkovskiy, Chien-Yao Wang, Hong-Yuan Mark Liao |
| 출판 |                       arXiv 2020                        |

- 깃헙 주소 : https://github.com/AlexeyAB/darknet

- yolo의 알고리즘은 Joseph Redmon이라는 사람에 의해 탄생했고 발전해왔지만, 2020년 2월 그는 다음과 같은 이유로 더이상 Computer Vision 분야를 연구하지 않겠다고 말했다.

  ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_creator.png)



### 연구 목적 및 연구 내용 요약

- 실시간 객체 검출 시스템은 더 많은 수의 GPU의 성능을 요구해왔다(배치 사이즈가 커지면 커질수록 많은 GPU가 필요하므로). 하지만 이 논문의 저자는 다양한 스킬을 사용하여 하나의 GPU에서도 모델의 성능을 좋게 만들었다.

  ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_perform.png)

- 이 논문의 주된 목표는 다음과 같다.

  1. 하나의 GPU로도 좋은 성능을 내는 것

     > 저자의 말에 따르면 1080Ti나 2080Ti 하나에서 아주 빠르고 정확한 객체검출을 할 수 있다고 한다.

  2. 최신 BOF(Bag of freebies), BOS(Bag of specials) 기법이 성능에 미치는 영향을 증명

  3. CBN, PAN, SAM을 포함한 기법을 활용하여 single GPU training에 최적화

     

- YOLOv4에서 사용된 최신 딥러닝 기법 : 

  1. WRC(Weighted-Residual-Connections)
  2. CSP(Cross-Stage-Partial-Connections)
  3. CBN(Cross mini-Batch Normalizations)
  4. SAT(Self-Adversarial-Training)
  5. Mish Activation
  6. Mosaic Data Augmentation
  7. Drop Block Regularization
  8. CIOU Loss



### 관련 연구(Related Work)

- 2.1. Object Detection Models : 

  이 절에서는 object detector들의 모델 구조에 대하여 설명하고 있다. 최신 detector는 feature map을 만드는 백본(backbone)과 class label, bounding box를 예측하는 헤드(Head)로 구성되어 있다.

  본 논문에서 사용한 백본과 헤드는 다음 그림에서 볼 수 있다.

  ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_model_structure.png)

  모델 구조를 살펴보면 백본과 헤드(prediction 구간) 사이에 넥(Neck)이 존재하는걸 볼 수 있다. 넥에서는 백본에서 추출된 feature map을 내가 사용할 데이터 형태에 맞게 재구성한다.

  대표적인 넥 구조로는 FPN(Feature Pyramid Network), PANet(Path Aggregation Network), Bi-FPN등이 있다.

  

- 2.2. Bag of Freebies(BOF) : 

  inference 중에 추가 계산 비용을 발생시키지 않으면서 object detection 네트워크의 성능을 향상시키기 위해 조합하여 사용할 수 있는 여러 가지 기법들을 통칭한 용어이다. 대표적인 BOF 기법은 다음과 같다.

  >  Inference refers to the process of using a trained machine learning algorithm to make a prediction

  1. **데이터 증강** : 

     (ex) CutMix, Mosaic 

  2. **BBox Regression의 loss함수** : 

     (ex) IOU loss, CIOU loss



- 2.3 Bag of Specials(BOS) : 

  이는 BOF와는 다르게 inference는 소폭 상승하지만 성능 향상이 되는 딥러닝 기법이다. 대표적인 BOS 기법은 다음과 같다.

  1. **receptive field의 증가** : 

     (ex) SPP([Spatial Pyramid Pooling](https://yeomko.tistory.com/14)), ASPP([Atrous Spatial Pyramid Pooling](https://gaussian37.github.io/vision-segmentation-aspp/)), RFB([Receptive Field Block](https://seongkyun.github.io/papers/2019/04/17/rfb_net/))

  2. **feature 통합** : 

     (ex) skip-connection, hyper-column, Bi-FPN

  3. **activation functions** 최적의 선택 : 

     (ex) ReLU, Mish



- 3.1. Selection of architecture : 

  저자는 본 절에서 입력 네트워크의 resolution,  conv layer의 수, parameter 수, 그리고 output의 수들 사이의 최적의 밸런스를 찾아내는것을 목표로 연구가 진행되었다고 말한다. 

  하지만 classification에 최적화된 기법들이 detector에서는 썩 좋은 성능을 내지 못하는 경우가 생긴다고 하는데, 

  1. 입력 네트워크가 큰 경우(higher resolution) : 여러개의 작은 물체를 검출하는데 문제가 생김
  2. 더 깊은 layer : layer가 깊어지면 feature size가 작아지므로, 보다 큰 receptive field를 위해서는 입력 이미지의 크기가 커야 함
  3. 더 많은 파라미터 : 한 이미지에서 다양한 크기의 여러 객체를 검출하기 위해서는 다수의 파라미터가 필요함

  단순히 이론적으로 생각해본다면, 더 큰 receptive field와 더 많은 파라미터를 갖는 네트워크가 백본으로 선택되어야 한다. 

  다음 표는 CSPResNeXt50, CSPDarknet53, EfficientNet-B3을 백본으로 사용할 경우의 파라미터 스펙이다.

  ![](/home/jon/Desktop/yolov4_백본.png)

  표에 의하면 receptive field size, parameter 수, output layer 크기들의 밸런스를 고려하면 CSPDarknet53이 가장 효과적이라고 한다.

  또한 백본뒤에 추가적으로 SPP 모듈을 더하고, 넥 구간에는 YOLOv3의 FPN과는 달리 PANet(Path-aggregation neck)을 사용하였으며, 헤드는 YOLOv3와 동일하게 구성하였다.

  

- 3.2. Selection of BOF and BOS : 

  YOLOv4에서는 다음과 같은 BOF를 사용하였다.

  1. **CutMix** : 데이터 증강법의 일종으로, 한 이미지에 2개의 class를 넣은것이 특징이다. 

     ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_cutmix.png)

     

  2. **Mosaic** Data Augmentation : CutMix와 마찬가지로 데이터 증강법의 일종으로, 한 이미지에 4개의 class를 넣은것이 특징이다.

     ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_mosaic.png)

     

     > 번외로 MixUp이라는 기법도 존재하는데, 이는 여러 이미지를 겹쳐서 입력으로 사용하는 방식이다.
     >
     > ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_mixup.png)

     

  3. **DropBlock** Regularization : DropOut과 같은 regularization 기법의 일종으로, 랜덤한 비율로 drop시키는 DropOut과 달리 feature의 일정 범위를 drop 한다.

     ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_dropblock_concept.png)

     알고리즘 구현 방법은 다음과 같으며, 이 [링크](https://arxiv.org/pdf/1810.12890.pdf)를 통해 자세한 논문을 읽어볼 수 있다.

     > DropBlock 논문 정리 참고자료 : https://norman3.github.io/papers/docs/dropblock.html

     ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_dropblock.png)

     

  4. Class **label Smoothing** : 

     라벨링의 새로운 방법으로, 기존의 라벨링은 정답이면 1, 아니면 0과 같은 딱 떨어지는 정수로 표현했지만 label smoothing 기법을 사용하면 label을 0.2, 0.8과 같은 확률로 표시할 수 있다. 

     이 기법을 통해 사람이 labeling을 한 데이터셋에서 발생할 수 있는 misslabeling에 대응할 수 있다. 결과적으로 calibration 및 regularization 효과를 얻게되어 overfitting문제를 방지할 수 있다고 한다.

     > tensorflow에서는 label smoothing에 대한 implementation을 제공한다. 아래와 같이 softmax_cross_entropy의 파라미터로 label_smoothing 값을 전달할 수 있다.
     >
     > ```python
     > tf.losses.softmax_cross_entropy(
     > 	onehot_labels,
     > 	logits,
     > 	weights=1.0,
     > 	label_smoothing=0,
     > 	scope=None,
     > 	loss_collection=tf.GraphKeys.LOSSES,
     >     reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
     > )
     > ```
     >
     > 만약 label_smoothing이 0이 아니면(클 수록 smoothing 증가), 다음과 같은 공식으로 smoothing이 진행된다.
     >
     > new_onehot_labels = onehot_labels * (1 - label_smoothing) + label_smoothing / num_classes
     >
     > 단 0 < label_smoothing < 1

  

  YOLOv4에서는 다음과 같은 BOS를 사용하였다.

  1. Mish Activation : 

     활성화 함수의 최신 기법중 하나로, 수식과 그래프는 다음과 같다.
     $$
     \\ f(x) = x \times tanh(ln(1+e^x))\\ 
     $$
     ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_mish.png)

     이 함수의 특징으로는

     - 범위가 [-0.31, $$\infty$$) 이다

     - 약간의 음수를 허용하기 때문에 ReLU보다 gradient의 흐름이 smooth하다

     - 그래프가 무한대로 뻗어나가기 때문에 0에 가까운 gradient로 인한 포화(Saturation)문제가 방지된다

       > Saturation : 0에 가까운 기울기로 인해 훈련 속도가 급격히 느려지는 현상

     - 함수의 형태가 아래로 볼록한 형태이기 때문에 strong regulariation이 발생하고, 이에 따라 overfitting 문제가 방지된다.

     - 참고자료 : https://eehoeskrap.tistory.com/440

     

  2. CSPNet(Cross-Stage Partial connections) : 

     기존 CNN 연산의 효율을 증가시키기 위해 개발된 기법으로, 학습할때 중복으로 사용되는 gradient정보를 버림으로써 연산량이 줄어들도록 하여 성능을 높였다고 한다.

     이 기법을 제시한 논문의 저자는 DenseNet을 사용하며 예시를 들었다. DenseNet의 매커니즘은 다음 그림과 같이 이전 layer의 정보를 그 하위 layer에 계속 연결지어주는 방식이다.

     ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_densnet.png)

     논문의 저자는 이 네트워크에서 역전파가 일어나며 가중치가 업데이트 되는 과정을 언급하며 다음과 같이 수많은 중복되는 gradient가 재사용 된다고 주장했다. 이들은 결국 중복된 gradient를 반복적으로 학습할 뿐이라고 말하며 이들을 제거해줄 필요성을 강조했다.

     ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_grad.png)

     따라서 이러한 문제를 다음과 같은 수식으로 중복되는 기울기를 제거했다고 한다.

     ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_CSP.png)

     그림과 함께 수식을 해석해 보면, Base layer의 출력값을 두개로 나누어(split) 두개의 grad-path를 만든다($$X_0 = [x_{0'}, x_{0''}]$$, $$x_{0'}$$ in part1, $$x_{0''}$$ in part2). 그 다음 part1은 바로 이 stage의 끝단과 연결되고, part2는 Dense Block을 지나게 된다. 

     part2에서 Dense Block을 지난 출력인 $$[x_{0''}, x_1,...,x_k]$$는 Transition layer를 통과한 출력값인 $$x_T$$는 윗단의 $$x_{0'}$$과 concatenate되어 또다른 Transition layer를 통과하고, 그 결과로 $$x_U$$를 얻게 된다.

     결과적으로 $$W_T'$$와 $$W_T''$$를 구성하는 gradient를 보면 서로 중복되지 않은것을이 사용된 것을 볼 수 있다.

     이때 Transition layer는 DenseNet에서 사용된것과 동일한데, 이 layer의 역할은 feature map의 사이즈와 개수를 줄이는 역할을 담당한다.

     DenseNet과 CSPnet의 차이점은 다음 그림을 통해 눈으로 확인할 수 있다.

     ![](https://raw.githubusercontent.com/Jonsuff/jonnote/master/images/yolov4/yolov4_dense_vs_csp.png)

     > 관련 논문 : https://arxiv.org/pdf/1911.11929.pdf

