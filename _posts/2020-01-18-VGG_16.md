---
layout: post
title:  "VGGNet"
date:   2020-01-18 15:40:13
categories: Deep_Learning
---

# VGG-16

- *Very Deep Convolutional Networks for Large-Scale Image Recognition* - Karen Simonyan & Andrew Zisserman

#### 특징

- *Smaller receptive field* - 작은 수용장(자극이 가해질때 자극을 감지하는 영역)을 사용한다. 

  AlexNet보다 작은 convolution filter를 사용한다.(3x3 필터 사용)

- *Depth* - convolution layer를 늘려 성능을 높인다.

- 논문에서 사용한 Architecture table

  ![ConvNet Table 1](https://raw.githubusercontent.com/Jonsuff/MLstudy/master/images/VGG-16 TABLE 1.png)

  - 3x3 필터를 지날 때 데이터를 유지하기 위해 1만큼의 padding을 한다.
  - 총 5번의 Max pooling을 사용한다. 이때 size =  2x2, stride = 2 이다.
  - Convolution layer와 pooling을 거친 데이터들은 총 3번의 Fully connected layer를 지나는데, 앞선 두 FC는 4096개의 채널을 가지고 마지막 FC는 1000개의 채널을 갖게 함으로써 1000개의 클래스 레이블을 만들어 이미지를 구별하도록 한다.
  - 최종적으로 soft-max layer를 통과한다.
  
- ReLU를 사용하여 처리속도를 빠르게 한다.



#### About Smaller Receptive Field

> *Smaller receptive field* - 작은 수용장(자극이 가해질때 자극을 감지하는 영역)을 사용한다. 

작은 필터를 여러번 사용하는 것은 큰 필터를 한번 사용하는것 보다 다음과 같은 이유로 유용하다.

1. 여러개의 필터를 통과하면 한개의 필터를 통과하는것 보다 결정함수 측면에서 식별하기 좋은 결과가 나타난다.

2. 파라미터 수를 줄일 수 있다. 

   예를 들어 3x3 필터 3번 사용할때와 7x7 필터 1개를 사용할때를 살펴보자. 필요한 파라미터 수를 계산하는 공식은 다음과 같다.
   $$
   Num(filter)(Size^2C^2)\\
   $$
   여기서 Num(filter)는 필터의 수를 의미하고 C는 convolution stack의 channel 개수를 의미한다.

   3x3 사이즈의 필터를 3번 사용할때 필요한 파라미터 수는 다음 연산을 통해 구할 수 있다.
   $$
   3(3^2C^2) = 27C^2\\
   $$
   만일 7x7 사이즈의 필터를 사용한다면 파라미터 수는 다음과 같다.
   $$
   1(7^2C^2) = 49C^2\\
   $$
   결과적으로 3x3 필터를 3번 사용했을때 필요한 파라미터의 수가 더 적은것을 알 수 있다.



#### The incorporation of 1x1 convolution layer

Table 1을 보면 3x3 convolution layer 이외에도 1x1 convolution layer를 사용한다. 이는 convolution layer의 receptive field에 영향을 끼치지 않으면서 결정함수의 비선형성을 증가하는데 도움을 준다.

> - 내 생각 
>
>   1x1 convolution은 입력과 출력 채널이 같아서 같은 차원에서의 linear projection이지만, 이를 ReLU를 사용하여 비선형 연산으로 바꾸어 비선형성을 부여한다.





#### Training

```
- batch size : 256

- momentum : 0.9

- L2 regularization : 5 x 10^-4

- learning rate : 10^-2 
  * validation set accuracy가 성능 향상을 멈출때 마다 10배 감소시킴 / 총 3번 감소 되었고 74 epochs(370K iteration)에서 학습을 멈춤.

- weight initialization : normal distribution w/ zero-mean 10^2 variance

- biases : 0

- input image : 224x224x3 (random crop, horizontal filpping and RGB color shift) from ImageNet image(256x256x3)
```

